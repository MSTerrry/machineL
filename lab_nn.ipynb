{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача\n",
    "Реализовать классификационную или регрессионную модель нейронной сеть, используя только средства numpy (и matplotlib для визуализации):\n",
    "1. Модель нейронной сети должна состоять из двух скрытых (внутренних) слоев ($k_1$ и $k_2$ - число нейронов скрытых слоев соответсвенно). \n",
    "2. Число нейронов в скрытых слоях выберите самостоятельно. Желательно реализовать выбор количества нейронов в скрытых слоях.\n",
    "3. Активационные функции в скрытых слоях выберите самостоятельно ('linear', 'sigmoid', 'tanh', 'relu'). \n",
    "4. Самостоятельно выбрать датасет для построения модели. Можно воспользоваться следующими данными:\n",
    "    - breast cancer wisconsin dataset (classification) sklearn.datasets.load_breast_cancer\n",
    "    - boston house-prices dataset (regression) sklearn.datasets.load_boston\n",
    "    - diabetes dataset (regression) sklearn.datasets.load_diabetes\n",
    "    - digits dataset (classification) sklearn.datasets.load_digits\n",
    "    Отвести 70% данных под тренировочную выборку, 20% под валидационную, 10% под тестовую.\n",
    "5. Реализовать прямой (forward) и обратный (backward) проходы по нейронной сети.\n",
    "6. Выбрать и реализовать оценки качества реализуемой модели (для классификации: accuracy, precision, recall, Fscore; для регрессии: mean absolute error (MAE))\n",
    "7. Обучить нейронную сеть на тренировочном наборе данных, на каждой эпохе обучения валидировать данные. Другими словами, необходимо выводить для каждой эпохи значения функции потерь и метрик точности для тренировочного и валидационного набора данных. Метрики необходимо строить на одном графике для оценки качества построенной модели.\n",
    "8. После тренировки модели необходимо протестировать модель на оставшемся наборе данных и сравнить все метрики для каждого набора данных.\n",
    "9. Сделать выводы\n",
    "\n",
    "Подсказки:\n",
    "- Обязательно сделайте нормализацию данных.\n",
    "- Веса внутренних слоев сгенерируйте случайным образов в диапазоне от $[-1, 1]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.data[:354]\n",
    "#Y = data.target[:354]\n",
    "#validX = data.data[354:455]\n",
    "#validY = data.target[354:455]\n",
    "#testX = data.data[455:]\n",
    "#testY = data.target[455:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_class = MinMaxScaler().fit_transform(Y_train_class.reshape(-1,1))\n",
    "#Y_train_regres = Y_train_regres.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston,load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "data = load_boston()\n",
    "def tahn(x, deriv = False):\n",
    "    if deriv == True:\n",
    "        return 1 - tahn(x)**2\n",
    "    return 2 / (1 + np.exp(-2*x)) - 1\n",
    "\n",
    "def sigmoid(x, deriv = False):\n",
    "    if deriv == True:\n",
    "        return sigmoid(x)*(1-sigmoid(x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def relu(x, deriv = False):\n",
    "    arr = x > 0\n",
    "    if deriv == True:\n",
    "        return arr.astype(float)\n",
    "    return arr.astype(float) * x\n",
    "def softmax(x, deriv = False):\n",
    "    if deriv == True:\n",
    "        return np.array([it * (1 - it) for it in x])\n",
    "    return np.array([np.exp(it) / np.sum(np.exp(it)) for it in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories(Y):\n",
    "    enc_y = []\n",
    "    for a in Y:\n",
    "        if a > 0.5:\n",
    "            enc_y.append([0,1])       \n",
    "        else:\n",
    "            enc_y.append([1,0])\n",
    "    return np.array(enc_y)\n",
    "def cross_entropy(y,q):\n",
    "    return -(y*np.log2(q)+(1-y)*np.log2(1-q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "Y = data.target\n",
    "activation = sigmoid\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "Y = MinMaxScaler().fit_transform(Y.reshape(-1,1))\n",
    "Y_class = categories(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "X_train_class, X_test_class, Y_train_class, Y_test_class     = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "X_train_regres, X_test_regres, Y_train_regres, Y_test_regres = train_test_split(X, Y_class, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y_class, y_regres):\n",
    "        # Входные данные #\n",
    "        np.random.seed(1)\n",
    "        self.input         = x\n",
    "        self.y_class       = y_class        \n",
    "        self.y_regres      = y_regres\n",
    "        self.output_class  = np.zeros(len(y_class))\n",
    "        self.output_regres = np.zeros(len(y_regres))        \n",
    "        self.lr = 0.001\n",
    "        self.weights_1 = 2*np.random.random((13,8)) - 1\n",
    "        self.weights_2_class = 2*np.random.random((8,2)) - 1\n",
    "        self.weights_2_regres = 2*np.random.random((8,4)) - 1\n",
    "        self.weights_out_class = 2*np.random.random((2,1)) - 1      \n",
    "        self.weights_out_regres = 2*np.random.random((4,2)) - 1      \n",
    "        # Прямой проход #\n",
    "    def FeedForward(self, x):            \n",
    "        self.out1 = activation(np.dot(x,self.weights_1))\n",
    "        self.out2_class = activation(np.dot(self.out1,self.weights_2_class))  \n",
    "        self.out2_regres = activation(np.dot(self.out1, self.weights_2_regres))\n",
    "        self.out_class = np.dot(self.out2_class,self.weights_out_class)#activation(\n",
    "        self.out_regres = softmax(np.dot(self.out2_regres, self.weights_out_regres))\n",
    "        return self.out_regres,self.out_class\n",
    "        \n",
    "        # Обратный проход #\n",
    "    def BackProp(self, x, y_class,y_regres):     \n",
    "        \n",
    "        out_error_3 = y_class-self.out_class\n",
    "        d_weights_3 = out_error_3 * activation(self.out_class, deriv=True)           \n",
    "        out_error_2 = d_weights_3.dot(self.weights_out_class.T)\n",
    "        d_weights_2 = out_error_2 * activation(self.out2_class, deriv=True)\n",
    "        out_error_1 = d_weights_2.dot(self.weights_2_class.T)\n",
    "        d_weights_1 = out_error_1 * activation(self.out1, deriv=True)\n",
    "        \n",
    "        out_error_3_reg = y_regres - self.out_regres\n",
    "        d_weights_3_reg  = out_error_3_reg * softmax(self.out_regres,True)#\n",
    "        out_error_2_reg = d_weights_3_reg.dot(self.weights_out_regres.T)\n",
    "        d_weights_2_reg = out_error_2_reg * activation(self.out2_regres, deriv=True)\n",
    "        out_error_1_reg = d_weights_2_reg.dot(self.weights_2_regres.T)\n",
    "        d_weights_1_reg = out_error_1_reg * activation(self.out1, deriv=True)\n",
    "\n",
    "        self.weights_1 += self.lr * self.input.T.dot(d_weights_1)\n",
    "        self.weights_1 += self.lr * self.input.T.dot(d_weights_1_reg)\n",
    "        self.weights_2_class += self.lr * np.dot(self.out1.T, d_weights_2)\n",
    "        self.weights_2_regres += self.lr * np.dot(self.out1.T, d_weights_2_reg)\n",
    "        self.weights_out_class += self.lr * np.dot(self.out2_class.T, d_weights_3)\n",
    "        self.weights_out_regres += self.lr * np.dot(self.out2_regres.T, d_weights_3_reg)\n",
    "        \n",
    "        # Тренировка #\n",
    "    def train(self, x, y_class, y_regres):\n",
    "        self.output_class, self.output_regres = self.FeedForward(x)#        \n",
    "        self.BackProp(x, y_class, y_regres)\n",
    "        \n",
    "    def Predict(self, x, y_class, y_regres):\n",
    "        print(x)\n",
    "        out1 = activation(np.dot(x,self.weights_1))\n",
    "        out2_class = activation(np.dot(out1,self.weights_2_class))  \n",
    "        out2_regres = activation(np.dot(out1, self.weights_2_regres))\n",
    "        out_class = np.dot(out2_class,self.weights_out_class)#activation(\n",
    "        out_regres = softmax(np.dot(out2_regres, self.weights_out_regres))\n",
    "        return out_class,out_regres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Loss: \n",
      "1.3529271905023077\n",
      "Regres Loss: \n",
      "0.6279200728286882\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.693521921105171\n",
      "Regres Loss: \n",
      "0.043320311207145204\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.6352042365318371\n",
      "Regres Loss: \n",
      "0.04040717647956292\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.5663899859828474\n",
      "Regres Loss: \n",
      "0.03343172067318924\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.5176791174257699\n",
      "Regres Loss: \n",
      "0.025529883489256784\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.47566592628980653\n",
      "Regres Loss: \n",
      "0.021086734212299396\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.40922450755481177\n",
      "Regres Loss: \n",
      "0.01760239413956523\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.3607912620319978\n",
      "Regres Loss: \n",
      "0.015217140318240925\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.33730966331585216\n",
      "Regres Loss: \n",
      "0.0140657812144276\n",
      "*******************************\n",
      "Class Loss: \n",
      "0.32511329793672455\n",
      "Regres Loss: \n",
      "0.013443731900878995\n",
      "*******************************\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(X_train_class,Y_train_class,Y_train_regres)\n",
    "epoch = 6500\n",
    "for i in range(epoch):\n",
    "    nn.train(X_train_class,Y_train_class,Y_train_regres)\n",
    "    if (i% round(epoch/10)) == 0:     \n",
    "        print (\"Class Loss: \\n\" + str(np.mean(cross_entropy(Y_train_regres,nn.out_regres))))  \n",
    "        print (\"Regres Loss: \\n\" + str(np.mean(np.square(Y_train_class - nn.out_class)))) # mean sum squared loss\n",
    "        print(\"*******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class Output: \n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Predicted Class Output: \n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "Actual Regres Output: \n",
      "[[0.34666667]\n",
      " [0.40222222]\n",
      " [0.51111111]\n",
      " [0.33333333]\n",
      " [0.40222222]\n",
      " [0.44444444]\n",
      " [0.10444444]\n",
      " [0.42      ]\n",
      " [0.69111111]\n",
      " [0.18666667]]\n",
      "Predicted Regres Output: \n",
      "[[0.36946975]\n",
      " [0.38421021]\n",
      " [0.51263743]\n",
      " [0.36245198]\n",
      " [0.41672496]\n",
      " [0.43956037]\n",
      " [0.21285166]\n",
      " [0.45760779]\n",
      " [0.6470444 ]\n",
      " [0.23969459]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Class Output: \\n\" + str(Y_train_regres[:10]))\n",
    "print(\"Predicted Class Output: \\n\" + str(nn.out_regres[:10].round()))\n",
    "print (\"Actual Regres Output: \\n\" + str(Y_train_class[:10]))\n",
    "print (\"Predicted Regres Output: \\n\" + str(nn.out_class[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.83309632e-04 3.30000000e-01 6.30498534e-02 ... 6.17021277e-01\n",
      "  1.00000000e+00 1.60044150e-01]\n",
      " [2.14791792e-04 5.50000000e-01 1.21700880e-01 ... 5.31914894e-01\n",
      "  1.00000000e+00 1.50386313e-01]\n",
      " [2.50590425e-03 0.00000000e+00 2.36436950e-01 ... 5.63829787e-01\n",
      "  9.89510313e-01 4.71026490e-01]\n",
      " ...\n",
      " [4.11937163e-04 5.25000000e-01 1.78152493e-01 ... 4.25531915e-01\n",
      "  9.36507136e-01 2.14679912e-01]\n",
      " [2.61661587e-03 0.00000000e+00 3.38343109e-01 ... 7.02127660e-01\n",
      "  1.00000000e+00 3.08774834e-01]\n",
      " [8.57930796e-04 0.00000000e+00 4.93401760e-01 ... 3.61702128e-01\n",
      "  1.00000000e+00 1.89017660e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class, y_pred_regres = nn.Predict(X_test_class, Y_test_class, Y_test_regres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Loss: \n",
      "0.3133735727167919\n",
      "Regres Loss: \n",
      "0.012752710700940514\n"
     ]
    }
   ],
   "source": [
    "print (\"Class Loss: \\n\" + str(np.mean(cross_entropy(Y_train_regres,nn.out_regres))))  \n",
    "print (\"Regres Loss: \\n\" + str(np.mean(np.square(Y_train_class - nn.out_class))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[-1.92135747]\n",
      " [-1.81462606]\n",
      " [-1.83578216]\n",
      " [-1.85073576]\n",
      " [-1.85609089]\n",
      " [-1.82688892]\n",
      " [-1.930663  ]\n",
      " [-1.91302331]\n",
      " [-1.91105521]\n",
      " [-1.91845563]]\n",
      "Class Loss: \n",
      "4.94681579943799\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n",
      "Ответы\n",
      "[[0.31937173]\n",
      " [0.2565445 ]\n",
      " [0.59947644]\n",
      " [0.56544503]\n",
      " [0.63874346]\n",
      " [0.44240838]\n",
      " [0.29057592]\n",
      " [0.40052356]\n",
      " [0.12303665]\n",
      " [0.18586387]]\n",
      "Выход после тренировки\n",
      "[[38.75080016]\n",
      " [38.99422554]\n",
      " [38.74209474]\n",
      " [38.45860368]\n",
      " [38.48621388]\n",
      " [38.64074524]\n",
      " [39.8505597 ]\n",
      " [39.97472207]\n",
      " [40.21985722]\n",
      " [40.00071926]]\n",
      "Class Loss: \n",
      "1536.3470484648856\n"
     ]
    }
   ],
   "source": [
    "epoch = 1500\n",
    "lr = 0.1\n",
    "np.random.seed(1)\n",
    "weights_1 = 2*np.random.random((13,25)) - 1\n",
    "weights_2 = 2*np.random.random((25,20)) - 1\n",
    "weights_3 = 2*np.random.random((20,1)) - 1\n",
    "\n",
    "error = []\n",
    "activation = sigmoid\n",
    "for i in range(epoch):\n",
    "    inp = X\n",
    "    out1 = activation(np.dot(inp,weights_1))\n",
    "    out2 = activation(np.dot(out1,weights_2))  \n",
    "    out3 = np.dot(out2,weights_3)\n",
    "    \n",
    "    out_error = (out3 - Y)**2\n",
    "    error.append(np.mean(out_error))\n",
    "    \n",
    "    out_error_3 = Y-out3    \n",
    "    d_weights_3 = out_error_3 * activation(out3, deriv=True)   \n",
    "    out_error_2 = d_weights_3.dot(weights_3.T)\n",
    "    d_weights_2 = out_error_2 * activation(out2, deriv=True)\n",
    "    out_error_1 = d_weights_2.dot(weights_2.T)\n",
    "    d_weights_1 = out_error_1 * activation(out1, deriv=True)\n",
    "    \n",
    "    \n",
    "    weights_1 += lr*inp.T.dot(d_weights_1)\n",
    "    weights_2 += lr * np.dot(out1.T, d_weights_2)\n",
    "    weights_3 += lr * np.dot(out2.T, d_weights_3)\n",
    "    if (i% round(epoch/10)) == 0:\n",
    "        print(\"Ответы\")\n",
    "        print(Y[:10])\n",
    "        print(\"Выход после тренировки\")\n",
    "        print(out3[:10])\n",
    "        print (\"Class Loss: \\n\" + str(np.mean(np.square(Y - out3))))\n",
    "#plt.plot(error)\n",
    "#print(\"Ответы\")\n",
    "#print(y[:10])\n",
    "#print(\"Выход после тренировки\")\n",
    "#print(out3[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
